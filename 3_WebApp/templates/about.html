{% extends 'index.html' %}

{% block body %}
    <div class="about_sec" style="text-align: left; padding: 20px;">
        <h2>üë®‚Äçüíª About The Creator</h2>
        <p>Hey, I‚Äôm Aakarsh Narang, an Information Technology undergraduate at IIIT Gwalior (2023‚Äì2027) with a passion for solving real-world problems through code and intelligent automation.
            </br></br>OCR Mind was born out of my curiosity to combine Computer Vision and Natural Language Processing into something tangible. I designed and built the entire system from the draggable canvas UI for precise document cropping, to the backend pipeline that performs OCR using Tesseract and custom entity extraction with SpaCy‚Äôs NER model, trained using BIO tagging on a curated set of 300+ business cards.
            </br></br>This project allowed me to apply my knowledge in areas like OpenCV, Flask, and front-end development, while pushing the boundaries of what a student-led prototype can achieve in document intelligence.
            </br></br>Alongside OCR Mind, I also explore AI tooling through projects like PromptSmith, which turns natural language prompts into code components using LLMs and Genkit.
            </br></br>I'm always looking for ways to improve this project, whether it's scaling the dataset, adding multi-document support, or deploying it as a public API. 
           </br></br> Feel free to explore, contribute, or reach out !!
        </br>
        </br>
            Name: &emsp;&nbsp;<span style="font-family: 'Michroma', sans-serif;">Aakarsh Narang</span>
        </br>
            E-Mail: <a href="mailto:aakarsh.narang2@gmail.com?subject=Regarding%20OCR%20Mind%20Project&body=Hi%20Aakarsh,%0A%0AI%20was%20checking%20out%20your%20OCR%20Mind%20project%20and...">
            aakarsh.narang2@gmail.com </a>
        </br>
            Phone: <a href="tel:+917454841288">+91 74548 41288</a>
    
        </p>
</br><hr></br>
        <h2>üìÑ About This Project</h2>
    <p>
        <strong>OCR Mind</strong> is an intelligent document scanner and entity extractor designed to scan business cards and automatically identify key information such as Name, Designation, Phone Number, Email, Organization, Website, and Location.
        <br><br>
        This project combines the power of Computer Vision and Natural Language Processing (NLP) to automate the extraction of structured data from unstructured scanned images. It was built by me as a student project to challenge and upgrade my machine learning and full-stack development skills.
        <br><br>
        Since this is a prototype trained on a relatively small dataset of just over 300 manually labeled business card samples, the system may not always provide highly accurate, algorithmically calculated coordinates when wrapping or cropping certain images. However, it consistently delivers impressive results when it comes to extracting and analyzing key data, especially in clean or moderately structured card layouts.
        <br><br>
        <strong>This is why the interface also allows you to manually select the coordinates for wrapping the image</strong> ‚Äî ensuring precision even when automated cropping has limitations.
        <br><br>
        The NER (Named Entity Recognition) model used in this project was trained from scratch using completely raw business card data. The data was cleaned, processed, and labeled through multiple stages of preprocessing and formatting. We used <strong>BIO tagging (Begin, Inside, Outside)</strong> to annotate each entity in the dataset accurately. This structured format allowed the model to learn and generalize entity recognition from highly diverse business card layouts.
    </p>

</br><hr></br>

    <h2>‚öôÔ∏è How It Works</h2>
    <h5>1. Image Upload and Region Selection:</h5>
    <p> Once a user uploads a business card image, the web interface provides four movable corner points, just like in professional document scanner apps. These draggable circles allow users to manually select the wrap or focus area of the card to remove unwanted borders, shadows, or distortions. This ensures the OCR engine works only on the relevant region of the document, greatly improving accuracy.</p>
</br>

    <h5>2. Image Preprocessing (Computer Vision):</h5>
    <p>The selected region is passed through various image processing techniques using OpenCV:</p>
    <ul style="list-style-type: none">
        <li>- Perspective transformation to flatten the image</li>
        <li>- Grayscale conversion, thresholding, and noise removal</li>
        <li>- Text enhancement to improve OCR clarity</li>
    </ul>
</br>

    <h5>3. Text Extraction with OCR:</h5>
    <p>The cleaned and preprocessed image is sent to Pytesseract, a Python wrapper for Google's Tesseract OCR engine. It converts the image into raw text that will then be passed to the NLP pipeline.</p>
</br>

    <h5>4. NER-Based Entity Extraction (NLP):</h5>
    <p>The extracted text is processed using a custom-trained Named Entity Recognition (NER) model built with SpaCy.
        We used BIO tagging (Begin-Inside-Outside) to manually label around 300 business card samples for training. This model is trained to identify specific categories like:</br>
        <code>B-NAME</code>, 
        <code>B-EMAIL</code>, 
        <code>B-PHONE</code>, 
        <code>B-DESIGNATION</code>, 
        <code>B-WEBSITE</code>, 
        etc.
    </p>
</br>
     <h5>5. Display and Output:</h5>
    <p>Once the text is parsed, the extracted entities are shown in a structured table format. The interface also optionally highlights the recognized fields using Displacy, SpaCy‚Äôs visualization tool.</p>

</br><hr></br>
    <h2>üìåWhy This Matters</h2>
    <p>Business cards may appear simple, but in reality, they are highly unstructured and vary significantly in design, layout, and content. Manually extracting relevant information like names, emails, phone numbers, and company details is both time-consuming and error-prone. Automating this process not only enhances accuracy but also boosts productivity, especially in large-scale scenarios.
       </br>This kind of automation can be a game-changer for several industries. It enables seamless integration with Customer Relationship Management (CRM) tools, improves lead management workflows, helps build searchable digital business card directories, and serves as a foundation for intelligent contact management systems. By leveraging OCR and Named Entity Recognition (NER), we take a step toward digitizing and organizing real-world information efficiently.
    </p>
</br><hr></br>

    <h2>üîó Built With</h2>
<ul style="list-style-type: none; padding-left: 20px; margin-left: 20px;">
  <li><strong>Python, Flask</strong> ‚Äì Backend processing & routing</li>
  <li><strong>OpenCV, Pytesseract</strong> ‚Äì Image handling and OCR</li>
  <li><strong>SpaCy</strong> ‚Äì Custom NER model</li>
  <li><strong>HTML, CSS, Bootstrap, JavaScript</strong> ‚Äì Web interface & interactivity</li>
  <li><strong>Draggable Canvas JS logic</strong> ‚Äì For selecting card region manually</li>
</ul>
</br><hr></br>
  <h2>üß¨ Future Improvements</h2>
  <p>
    While this is currently a <strong>prototype trained on 300 manually labeled business cards</strong>, the system is built with scalability in mind. Here‚Äôs how it can be improved further:
  </p>
  <ul style="list-style-type: none">
    <li>1. Train the NER model on a <strong>larger, more diverse dataset</strong> for higher accuracy across different layouts, fonts, and languages</li>
    <li>2. Support for other document types like <strong>invoices, ID cards, shipping bills, and forms</strong></li>
    <li>3. Integrate <strong>deep learning OCR engines</strong> like EasyOCR or PaddleOCR for better text recognition</li>
    <li>4. Add <strong>auto-cropping with edge detection</strong> so users don‚Äôt need to manually adjust the corners every time</li>
    <li>5. Deploy as a <strong>cloud-based API or full-stack SaaS</strong> tool for real-world business integration</li>
  </ul>
<hr>
    
</div>

{% endblock body %}